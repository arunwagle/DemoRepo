{
    "metadata": {
        "language_info": {
            "name": "python", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2", 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "name": "python2-spark20", 
            "display_name": "Python 2 with Spark 2.0", 
            "language": "python"
        }
    }, 
    "cells": [
        {
            "execution_count": 13, 
            "source": "!pip install --user xlrd", 
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Requirement already satisfied: xlrd in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s1df-1767d8774d3251-73caa6cfaa60/.local/lib/python2.7/site-packages\r\n"
                }
            ]
        }, 
        {
            "execution_count": 3, 
            "source": "import Common_Functions\n\n\nfundDF = pd.read_excel(Common_Functions.getFileFromObjectStorage('MizuhoPOC', 'Funds.xlsm'),header=[0]).rename(index=str, columns={\"ALADDIN\": \"ID\"})\nfundDF.head(5)", 
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-be4853edaa4a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import Mizuho-POC.Common_Functions\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ], 
                    "evalue": "invalid syntax (<ipython-input-3-be4853edaa4a>, line 1)", 
                    "ename": "SyntaxError", 
                    "output_type": "error"
                }
            ]
        }, 
        {
            "execution_count": 14, 
            "source": "import pandas as pd\nfrom io import BytesIO\nimport requests\nimport json\nimport xlrd \n\nfrom pyspark.sql.functions import *\nfrom datetime import datetime\nfrom dateutil.parser import parse\n\nfrom ingest.Connectors import Connectors", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": 15, 
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": 16, 
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "execution_count": 17, 
            "source": "\nfundDF = pd.read_excel(getFileFromObjectStorage('MizuhoPOC', 'Funds.xlsm'),header=[0]).rename(index=str, columns={\"ALADDIN\": \"ID\"})\nfundDF.head(5)\n\n", 
            "metadata": {
                "scrolled": true
            }, 
            "cell_type": "code", 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "        ID\n0    I-CJF\n1    I-CGF\n2    I-HFR\n3    I-HMC\n4  I-SABF1", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I-CJF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I-CGF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I-HFR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I-HMC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I-SABF1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "execution_count": 18, 
            "source": "spark = SparkSession.builder.getOrCreate()  \n\nmhcbSparkDF = spark.createDataFrame(fundDF)\n\n\nmhcbSparkDF.printSchema()\n\n\n# Connection to Dash DB for writing the data\ndashdbsaveoption = {\n                     Connectors.DASHDB.HOST              : dashCredentials[\"host\"],\n                     Connectors.DASHDB.DATABASE          : dashCredentials[\"db\"],\n                     Connectors.DASHDB.USERNAME          : dashCredentials[\"username\"],\n                     Connectors.DASHDB.PASSWORD          : dashCredentials[\"password\"],\n                     Connectors.DASHDB.TARGET_TABLE_NAME : dashCredentials[\"tableName\"],\n                     Connectors.DASHDB.TARGET_WRITE_MODE : 'merge' \n}\n\nmhcbDashDBDF = mhcbSparkDF.write.format(\"com.ibm.spark.discover\").options(**dashdbsaveoption).save()\n", 
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- ID: string (nullable = true)\n\n"
                }
            ]
        }, 
        {
            "execution_count": null, 
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat": 4, 
    "nbformat_minor": 1
}